apiVersion: vllm.efortin.github.io/v1alpha1
kind: VLLMModel
metadata:
  name: deepseek-r1-fp8
  namespace: ai-apps
spec:
  # Model Identification
  modelName: "neuralmagic/DeepSeek-R1-Distill-Qwen-32B-FP8-dynamic"
  servedModelName: "deepseek-r1-fp8"
  
  # Parsing Configuration
  toolCallParser: "hermes"
  reasoningParser: "deepseek_r1"
  
  # vLLM Runtime Parameters
  tensorParallelSize: 2
  maxModelLen: 65536
  gpuMemoryUtilization: 0.91
  enableChunkedPrefill: true
  maxNumBatchedTokens: 4096
  maxNumSeqs: 16
  dtype: "float16"
  disableCustomAllReduce: true
  enablePrefixCaching: true
  cpuOffloadGB: 0
  enableAutoToolChoice: true
